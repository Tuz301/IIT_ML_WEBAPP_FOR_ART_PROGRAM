# =============================================================================
# IIT ML Service - Production Docker Compose Configuration
# =============================================================================
# This file contains all services required for production deployment
# Usage: docker-compose -f docker-compose.production.yml up -d
# =============================================================================

version: '3.8'

services:
  # =============================================================================
  # Nginx Reverse Proxy with SSL
  # =============================================================================
  nginx:
    image: nginx:alpine
    container_name: iit-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - ./dist:/usr/share/nginx/html:ro
    depends_on:
      - backend
    restart: unless-stopped
    networks:
      - iit-network
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # =============================================================================
  # FastAPI Backend Service
  # =============================================================================
  backend:
    build:
      context: ./backend/ml-service
      dockerfile: Dockerfile
    container_name: iit-backend
    env_file:
      - ./backend/ml-service/.env.production
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      - REDIS_URL=redis://redis:6379/0
    volumes:
      - ./backend/ml-service/models:/app/models:ro
      - ./backend/ml-service/logs:/app/logs
      - ./backups:/app/backups
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - iit-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # =============================================================================
  # RQ Worker for Background Jobs
  # =============================================================================
  worker:
    build:
      context: ./backend/ml-service
      dockerfile: Dockerfile
    container_name: iit-worker
    command: python -m rq worker --url redis://redis:6379/0 --logging-level INFO
    env_file:
      - ./backend/ml-service/.env.production
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      - REDIS_URL=redis://redis:6379/0
    volumes:
      - ./backend/ml-service/models:/app/models:ro
      - ./backend/ml-service/logs:/app/logs
      - ./backups:/app/backups
    depends_on:
      - postgres
      - redis
    restart: unless-stopped
    networks:
      - iit-network

  # =============================================================================
  # PostgreSQL Database
  # =============================================================================
  postgres:
    image: postgres:16-alpine
    container_name: iit-postgres
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-iit_ml_service}
      POSTGRES_USER: ${POSTGRES_USER:-ml_service_user}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-CHANGE_THIS_STRONG_PASSWORD}
      POSTGRES_INITDB_ARGS: "-E UTF8 --locale=en_US.UTF-8"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./backups/postgres:/backups
    ports:
      - "5432:5432"
    restart: unless-stopped
    networks:
      - iit-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-ml_service_user}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    shm_size: 256mb

  # =============================================================================
  # Redis Cache & Queue
  # =============================================================================
  redis:
    image: redis:7-alpine
    container_name: iit-redis
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD:-}
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    restart: unless-stopped
    networks:
      - iit-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 20s

  # =============================================================================
  # Jaeger Distributed Tracing
  # =============================================================================
  jaeger:
    image: jaegertracing/all-in-one:latest
    container_name: iit-jaeger
    environment:
      - COLLECTOR_OTLP_ENABLED=true
      - SPAN_STORAGE_TYPE=elasticsearch
    ports:
      - "5775:5775/udp"    # accept zipkin.thrift over compact thrift protocol
      - "6831:6831/udp"    # accept jaeger.thrift over compact thrift protocol
      - "6832:6832/udp"    # accept jaeger.thrift over binary thrift protocol
      - "5778:5778"        # serve configs
      - "16686:16686"      # serve frontend (Jaeger UI)
      - "14268:14268"      # HTTP collector
      - "14250:14250"      # gRPC collector
      - "9411:9411"        # accept Zipkin compatible endpoints
    restart: unless-stopped
    networks:
      - iit-network

  # =============================================================================
  # Prometheus Metrics
  # =============================================================================
  prometheus:
    image: prom/prometheus:latest
    container_name: iit-prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./monitoring/prometheus-alerts.yml:/etc/prometheus/alerts.yml:ro
      - prometheus_data:/prometheus
    ports:
      - "9090:9090"
    restart: unless-stopped
    networks:
      - iit-network
    depends_on:
      - backend

  # =============================================================================
  # Grafana Dashboards
  # =============================================================================
  grafana:
    image: grafana/grafana:latest
    container_name: iit-grafana
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana-dashboard-ml-service.json:/etc/grafana/provisioning/dashboards/iit-ml-service.json:ro
      - ./monitoring/grafana-datasources.yml:/etc/grafana/provisioning/datasources/prometheus.yml:ro
    ports:
      - "3000:3000"
    restart: unless-stopped
    networks:
      - iit-network
    depends_on:
      - prometheus

  # =============================================================================
  # Automated Backup Service
  # =============================================================================
  backup:
    image: postgres:16-alpine
    container_name: iit-backup
    volumes:
      - ./backups/postgres:/backups
      - ./scripts/backup.sh:/backup.sh:ro
    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_DB=${POSTGRES_DB:-iit_ml_service}
      - POSTGRES_USER=${POSTGRES_USER:-ml_service_user}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-CHANGE_THIS_STRONG_PASSWORD}
      - BACKUP_RETENTION_DAYS=30
    command: /bin/sh -c "chmod +x /backup.sh && crond -f -l 2 && tail -f /var/log/cron.log"
    restart: unless-stopped
    networks:
      - iit-network
    depends_on:
      - postgres

networks:
  iit-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
